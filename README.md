# alpaca_for_kg

This is a forked and modified repository of [stanford_alpaca](https://github.com/tatsu-lab/stanford_alpaca), adapted for geoscience data analysis workflow synthetic data generation for fine-tuning.

You can find the fine-tuning code and the fine-tuned model information in the repository: [Llama_MindatWorkflow](https://github.com/ChuBL/Llama_MindatWorkflow)

## Usage

The entry point of the project is `generate_instruction_v4.py`.

## Citation

If you use this code in your research, please cite our work:

```bibtex
@misc{zhang2024fine,
  title={Fine-Tuning Small and Open {LLMs} to Automate Geoscience Data Analysis Workflows: A Scalable Approach},
  author={Zhang, Jiyin and Li, Wenjia and Que, Xiang and Chen, Weilin and Li, Chenhao and Ma, Xiaogang},
  howpublished={Available at SSRN},
  note={SSRN 5065689},
  year={2024},
  month={December},
  doi={10.2139/ssrn.5065689},
  keywords={Open LLM, Fine tuning, Mindat, Data analytics, Data science}
}
```

**Paper:** [Fine-Tuning Small and Open LLMs to Automate Geoscience Data Analysis Workflows: A Scalable Approach](https://doi.org/10.2139/ssrn.5065689)